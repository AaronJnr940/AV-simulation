Automated Generation of Test Scenarios for Autonomous Driving using LLMs

Abstract: In this paper, an approach that uses large language models (LLMs) to turn detailed descriptions of an Operational Design Domain (ODD) into realistic, executa-ble simulation scenarios for testing autonomous vehicles is introduced. The method blends model-based and data-driven techniques to break down ODDs into three main parts; environmental, scenery, and dynamic and then uses prompt engineering tech-niques to create ScenarioRunner scripts that work with CARLA. Essentially, the mod-el-based aspect guides the LLM with structured prompts and a “Tree of Thoughts” strategy to outline the scenario, while a data-driven refinement process drawing in-spiration from red teaming helps improve the accuracy and robustness of the generat-ed scripts over time. The experiments show that while static components like weather and road layouts are captured very well, dynamic elements such as vehicle and pedes-trian behavior still need some fine-tuning. Overall, the work not only reduces the manual effort involved in creating these simulation scenarios, but also highlights challenges and opportunities for future improvements for more adaptable and safer autonomous driving systems. 

Keywords: large language models; generation, Operational Design Domain; autono-mous vehicles; simulation; CARLA; ScenarioRunner; prompt-engineering; fine-tuning 
